{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sitemap found at: https://www.artificialintelligence-news.com/sitemap.xml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def find_sitemap(url):\n",
    "  \"\"\"Searches for a website's sitemap using various methods.\n",
    "\n",
    "  Args:\n",
    "      url (str): The base URL of the website.\n",
    "\n",
    "  Returns:\n",
    "      str: The URL of the sitemap if found, otherwise None.\n",
    "  \"\"\"\n",
    "\n",
    "  # Common sitemap locations\n",
    "  sitemap_urls = [\n",
    "      urljoin(url, '/sitemap.xml'),\n",
    "      urljoin(url, '/sitemap_index.xml'),\n",
    "  ]\n",
    "\n",
    "  # Check robots.txt for sitemap reference\n",
    "  robots_url = urljoin(url, '/robots.txt')\n",
    "  try:\n",
    "    response = requests.get(robots_url)\n",
    "    if response.status_code == 200:\n",
    "      for line in response.text.splitlines():\n",
    "        if line.lower().startswith('sitemap:'):\n",
    "          sitemap_urls.append(line.split(':')[1].strip())\n",
    "  except requests.exceptions.RequestException:\n",
    "    pass  # Ignore errors fetching robots.txt\n",
    "\n",
    "  # Try Google search operators (less reliable)\n",
    "  search_url = f\"site:{url} filetype:xml inurl:sitemap\"\n",
    "  try:\n",
    "    response = requests.get(search_url)\n",
    "    if response.status_code == 200:\n",
    "      for link in response.text.iterlinks():\n",
    "        if link[0].endswith('.xml'):\n",
    "          sitemap_urls.append(link[0])\n",
    "  except requests.exceptions.RequestException:\n",
    "    pass  # Ignore errors with Google search\n",
    "\n",
    "  # Check each potential sitemap URL\n",
    "  for sitemap_url in sitemap_urls:\n",
    "    try:\n",
    "      response = requests.get(sitemap_url)\n",
    "      if response.status_code == 200 and response.headers['Content-Type'].startswith('text/xml'):\n",
    "        return sitemap_url\n",
    "    except requests.exceptions.RequestException:\n",
    "      pass  # Ignore errors fetching potential sitemaps\n",
    "\n",
    "  return None\n",
    "\n",
    "# Example usage\n",
    "website_url = \"https://www.artificialintelligence-news.com/\"\n",
    "sitemap_url = find_sitemap(website_url)\n",
    "\n",
    "if sitemap_url:\n",
    "  print(f\"Sitemap found at: {sitemap_url}\")\n",
    "else:\n",
    "  print(\"Sitemap not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='www.artificialintelligence-news.com', path='/sitemap.xml', params='', query='', fragment='')\n",
      "Sitemap downloaded successfully to: example_sitemaps\\www_artificialintelligence-news_com_sitemap.xml\n",
      "You can access the downloaded sitemap at: example_sitemaps\\www_artificialintelligence-news_com_sitemap.xml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def download_sitemap(url, save_dir):\n",
    "  \"\"\"Downloads the sitemap from the given URL and saves it to the specified directory.\n",
    "\n",
    "  Args:\n",
    "      url (str): The URL of the sitemap to download.\n",
    "      save_dir (str): The directory to save the downloaded sitemap.\n",
    "\n",
    "  Returns:\n",
    "      str: The path to the saved sitemap file, or None if an error occurred.\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      # Extract filename from URL\n",
    "      parsed_url = urlparse(url)\n",
    "      print(parsed_url)\n",
    "      filename_components = parsed_url.netloc.split('.')\n",
    "      filename = '_'.join(filename_components)\n",
    "      if not filename:  # Handle cases where URL path ends with '/'\n",
    "        filename = os.path.basename(parsed_url.path[:-1])  # Get path segment before trailing '/'\n",
    "\n",
    "      # Create filename with appropriate extension (assuming XML for sitemaps)\n",
    "      sitemap_filename = f\"{filename}_sitemap.xml\"\n",
    "\n",
    "      # Create save path\n",
    "      save_path = os.path.join(save_dir, sitemap_filename)\n",
    "\n",
    "      with open(save_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "      print(f\"Sitemap downloaded successfully to: {save_path}\")\n",
    "      return save_path  # Return the path for potential use\n",
    "\n",
    "    else:\n",
    "      print(f\"Failed to download sitemap. Status code: {response.status_code}\")\n",
    "      return None  # Indicate failure\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    return None  # Indicate failure\n",
    "\n",
    "sitemap_dir = \"example_sitemaps\"\n",
    "\n",
    "# Create the directory if it doesn't exist (improved error handling)\n",
    "try:\n",
    "  os.makedirs(sitemap_dir, exist_ok=True)  # Suppress errors if directory already exists\n",
    "except OSError as e:\n",
    "  print(f\"Error creating directory: {e}\")\n",
    "  exit(1)  # Exit with an error code if directory creation fails\n",
    "\n",
    "url = \"https://www.artificialintelligence-news.com/sitemap.xml\"\n",
    "\n",
    "saved_sitemap_path = download_sitemap(url, sitemap_dir)\n",
    "\n",
    "if saved_sitemap_path:\n",
    "  print(f\"You can access the downloaded sitemap at: {saved_sitemap_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Element: {http://www.sitemaps.org/schemas/sitemap/0.9}urlset\n",
      "Attributes: {}\n",
      "Children of Root Element:\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('example_sitemaps\\llamaindex_sitemap.xml')\n",
    "\n",
    "# Get the root element\n",
    "root = tree.getroot()\n",
    "\n",
    "# Print the root element tag and attributes\n",
    "print(\"Root Element:\", root.tag)\n",
    "print(\"Attributes:\", root.attrib)\n",
    "\n",
    "# Print the children of the root element\n",
    "print(\"Children of Root Element:\")\n",
    "for child in root:\n",
    "    print(child.tag, child.attrib)\n",
    "\n",
    "# Print the text content of elements along with the href attribute\n",
    "for element in root.iter():\n",
    "    if 'href' in element.attrib:\n",
    "        print(element.tag, \":\", element.attrib['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sitemap: https://www.artificialintelligence-news.com/post-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/post-sitemap2.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/page-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/events-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/resources-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/videos-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/category-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/post_tag-sitemap.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/post_tag-sitemap2.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/post_tag-sitemap3.xml\n",
      "Found sitemap: https://www.artificialintelligence-news.com/author-sitemap.xml\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "\n",
    "def parse_sitemap(url):\n",
    "    response = requests.get(url)\n",
    "    # Ensure the response is in XML format\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the XML content\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    # Dynamically find the namespace\n",
    "    namespace = ''\n",
    "    if root.tag.startswith('{'):\n",
    "        namespace = root.tag.split('}')[0] + '}'\n",
    "\n",
    "    # Check if this is a sitemap index or an actual sitemap\n",
    "    if root.tag == f'{namespace}sitemapindex':\n",
    "        # If it's a sitemap index, iterate through each sitemap listed and repeat\n",
    "        for sitemap in root.findall(f'{namespace}sitemap'):\n",
    "            loc = sitemap.find(f'{namespace}loc').text\n",
    "            print(f'Found sitemap: {loc}')\n",
    "            # Optionally, you can call parse_sitemap(loc) recursively to parse nested sitemaps\n",
    "    else:\n",
    "        # If it's an actual sitemap, iterate through each URL listed\n",
    "        for url in root.findall(f'{namespace}url'):\n",
    "            loc = url.find(f'{namespace}loc').text\n",
    "            print(f'Found URL: {loc}')\n",
    "\n",
    "# Example usage\n",
    "sitemap_url = 'https://www.artificialintelligence-news.com/sitemap_index.xml'\n",
    "parse_sitemap(sitemap_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
