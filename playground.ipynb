{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sitemap found at: https://www.artificialintelligence-news.com/sitemap.xml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def find_sitemap(url):\n",
    "  \"\"\"Searches for a website's sitemap using various methods.\n",
    "\n",
    "  Args:\n",
    "      url (str): The base URL of the website.\n",
    "\n",
    "  Returns:\n",
    "      str: The URL of the sitemap if found, otherwise None.\n",
    "  \"\"\"\n",
    "\n",
    "  # Common sitemap locations\n",
    "  sitemap_urls = [\n",
    "      urljoin(url, '/sitemap.xml'),\n",
    "      urljoin(url, '/sitemap_index.xml'),\n",
    "  ]\n",
    "\n",
    "  # Check robots.txt for sitemap reference\n",
    "  robots_url = urljoin(url, '/robots.txt')\n",
    "  try:\n",
    "    response = requests.get(robots_url)\n",
    "    if response.status_code == 200:\n",
    "      for line in response.text.splitlines():\n",
    "        if line.lower().startswith('sitemap:'):\n",
    "          sitemap_urls.append(line.split(':')[1].strip())\n",
    "  except requests.exceptions.RequestException:\n",
    "    pass  # Ignore errors fetching robots.txt\n",
    "\n",
    "  # Try Google search operators (less reliable)\n",
    "  search_url = f\"site:{url} filetype:xml inurl:sitemap\"\n",
    "  try:\n",
    "    response = requests.get(search_url)\n",
    "    if response.status_code == 200:\n",
    "      for link in response.text.iterlinks():\n",
    "        if link[0].endswith('.xml'):\n",
    "          sitemap_urls.append(link[0])\n",
    "  except requests.exceptions.RequestException:\n",
    "    pass  # Ignore errors with Google search\n",
    "\n",
    "  # Check each potential sitemap URL\n",
    "  for sitemap_url in sitemap_urls:\n",
    "    try:\n",
    "      response = requests.get(sitemap_url)\n",
    "      if response.status_code == 200 and response.headers['Content-Type'].startswith('text/xml'):\n",
    "        return sitemap_url\n",
    "    except requests.exceptions.RequestException:\n",
    "      pass  # Ignore errors fetching potential sitemaps\n",
    "\n",
    "  return None\n",
    "\n",
    "# Example usage\n",
    "website_url = \"https://www.artificialintelligence-news.com/\"\n",
    "sitemap_url = find_sitemap(website_url)\n",
    "\n",
    "if sitemap_url:\n",
    "  print(f\"Sitemap found at: {sitemap_url}\")\n",
    "else:\n",
    "  print(\"Sitemap not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sitemap downloaded successfully to: example_sitemaps_new\\sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\post-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\page-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\jet-menu-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\treatments-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\mental-health-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\california-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\team-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\therapy-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\program-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\category-sitemap.xml\n",
      "Sitemap downloaded successfully to: example_sitemaps_new\\author-sitemap.xml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import xml.etree.ElementTree as ET  # For parsing XML content of sitemaps\n",
    "\n",
    "# Headers for each request\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def find_potential_sitemap_urls(xml_content):\n",
    "    \"\"\"Parses XML content for sitemap URLs and filters potential XML sitemap URLs based on simple heuristics.\n",
    "\n",
    "    Args:\n",
    "        xml_content (str): The XML content of a sitemap.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of potential sitemap URLs based on naming heuristics.\n",
    "    \"\"\"\n",
    "    root = ET.fromstring(xml_content)\n",
    "    namespace = {'sitemap': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "    # Look for <loc> tags within <sitemap> elements\n",
    "    urls = [elem.text for elem in root.findall('.//sitemap:loc', namespaces=namespace)]\n",
    "\n",
    "    # Filter out URLs that are likely to be XML based on their patterns\n",
    "    likely_xml_urls = [url for url in urls if url.endswith('.xml') or 'sitemap' in url.lower()]\n",
    "\n",
    "    return likely_xml_urls\n",
    "\n",
    "def check_if_xml(urls, headers):\n",
    "    \"\"\"Check if the given URLs are XML sitemaps by making network requests.\n",
    "\n",
    "    Args:\n",
    "        urls (list): A list of URLs to check.\n",
    "        headers (dict): Request headers.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of URLs confirmed to be XML sitemaps.\n",
    "    \"\"\"\n",
    "    xml_urls = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            content_type = response.headers.get('content-type', '')\n",
    "            if content_type.startswith('text/xml'):\n",
    "                xml_urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching URL {url}: {e}\")\n",
    "\n",
    "    return xml_urls\n",
    "\n",
    "def download_sitemap(url, save_dir, downloaded_urls):\n",
    "    \"\"\"Downloads the sitemap from the given URL and saves it to the specified directory.\n",
    "    Recursively downloads any child sitemaps.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the sitemap to download.\n",
    "        save_dir (str): The directory to save the downloaded sitemap.\n",
    "        downloaded_urls (set): A set of URLs already downloaded to prevent duplicates.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if url in downloaded_urls:\n",
    "        print(f\"Skipping already downloaded sitemap: {url}\")\n",
    "        return  # Avoid re-downloading sitemaps\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            # Extract filename from URL\n",
    "            parsed_url = urlparse(url)\n",
    "            filename = os.path.basename(parsed_url.path) or 'index'\n",
    "            # Create filename with appropriate extension (assuming XML for sitemaps)\n",
    "            sitemap_filename = f\"{filename}\"\n",
    "            # Create save path\n",
    "            save_path = os.path.join(save_dir, sitemap_filename)\n",
    "\n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Sitemap downloaded successfully to: {save_path}\")\n",
    "\n",
    "            downloaded_urls.add(url)  # Mark this URL as downloaded\n",
    "\n",
    "            child_potential_sitemap_urls = find_potential_sitemap_urls(response.content.decode())\n",
    "            child_sitemap_urls = check_if_xml(child_potential_sitemap_urls,headers=headers)\n",
    "            for child_url in child_sitemap_urls:\n",
    "                download_sitemap(child_url, save_dir, downloaded_urls)\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to download sitemap. Status code: {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "sitemap_dir = \"example_sitemaps_new\"\n",
    "\n",
    "# Create the directory if it doesn't exist (improved error handling)\n",
    "try:\n",
    "    os.makedirs(sitemap_dir, exist_ok=True)\n",
    "except OSError as e:\n",
    "    print(f\"Error creating directory: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# URL of the sitemap\n",
    "sitemap_url = \"https://www.mytimerecovery.com/sitemap.xml\"\n",
    "\n",
    "downloaded_urls = set()  # To track downloaded URLs\n",
    "download_sitemap(sitemap_url, sitemap_dir, downloaded_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sitemap Status: 403\n",
      "Sitemap Content: <html>\n",
      "<head><title>403 Forbidden</title></head>\n",
      "<body>\n",
      "<center><h1>403 Forbidden</h1></center>\n",
      "<hr><center>nginx</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the sitemap\n",
    "sitemap_url = \"https://www.mytimerecovery.com/sitemap.xml\"\n",
    "# Headers for each request\n",
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Make requests\n",
    "response_sitemap = requests.get(sitemap_url, headers=headers)\n",
    "\n",
    "\n",
    "# Check responses\n",
    "print(\"Sitemap Status:\", response_sitemap.status_code)\n",
    "\n",
    "\n",
    "# Uncomment below to print content\n",
    "print(\"Sitemap Content:\", response_sitemap.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Element: {http://www.sitemaps.org/schemas/sitemap/0.9}urlset\n",
      "Attributes: {}\n",
      "Children of Root Element:\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n",
      "{http://www.sitemaps.org/schemas/sitemap/0.9}url {}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('example_sitemaps\\llamaindex_sitemap.xml')\n",
    "\n",
    "# Get the root element\n",
    "root = tree.getroot()\n",
    "\n",
    "# Print the root element tag and attributes\n",
    "print(\"Root Element:\", root.tag)\n",
    "print(\"Attributes:\", root.attrib)\n",
    "\n",
    "# Print the children of the root element\n",
    "print(\"Children of Root Element:\")\n",
    "for child in root:\n",
    "    print(child.tag, child.attrib)\n",
    "\n",
    "# Print the text content of elements along with the href attribute\n",
    "for element in root.iter():\n",
    "    if 'href' in element.attrib:\n",
    "        print(element.tag, \":\", element.attrib['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.mytimerecovery.com/sitemap_index.xml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     31\u001b[0m sitemap_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.mytimerecovery.com/sitemap_index.xml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mparse_sitemap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msitemap_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m, in \u001b[0;36mparse_sitemap\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Ensure the response is in XML format\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Parse the XML content\u001b[39;00m\n\u001b[0;32m     10\u001b[0m root \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mfromstring(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32me:\\DESKTOP\\FreeLanceProjects\\Vxtint\\GenerativeSearchAI\\venv\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.mytimerecovery.com/sitemap_index.xml"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "\n",
    "def parse_sitemap(url):\n",
    "    response = requests.get(url)\n",
    "    # Ensure the response is in XML format\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse the XML content\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    # Dynamically find the namespace\n",
    "    namespace = ''\n",
    "    if root.tag.startswith('{'):\n",
    "        namespace = root.tag.split('}')[0] + '}'\n",
    "\n",
    "    # Check if this is a sitemap index or an actual sitemap\n",
    "    if root.tag == f'{namespace}sitemapindex':\n",
    "        # If it's a sitemap index, iterate through each sitemap listed and repeat\n",
    "        for sitemap in root.findall(f'{namespace}sitemap'):\n",
    "            loc = sitemap.find(f'{namespace}loc').text\n",
    "            print(f'Found sitemap: {loc}')\n",
    "            # Optionally, you can call parse_sitemap(loc) recursively to parse nested sitemaps\n",
    "    else:\n",
    "        # If it's an actual sitemap, iterate through each URL listed\n",
    "        for url in root.findall(f'{namespace}url'):\n",
    "            loc = url.find(f'{namespace}loc').text\n",
    "            print(f'Found URL: {loc}')\n",
    "\n",
    "# Example usage\n",
    "sitemap_url = 'https://www.mytimerecovery.com/sitemap_index.xml'\n",
    "parse_sitemap(sitemap_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html><head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "\n",
      "\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "payload = { 'api_key': 'm', 'url': 'https://example.com', 'render': True, 'country_code': 'us', 'device_type': 'desktop' }\n",
    "r = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "print(r.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
